{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ke535ihVDOOH",
        "outputId": "b78d3f50-51ba-4918-f279-0b0cefbed4ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yB3Y_S2XSLEJ",
        "outputId": "b2f5c994-27dd-4910-f5a9-e2e28d7ad7e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19432979\n"
          ]
        }
      ],
      "source": [
        "with open('/content/drive/MyDrive/TinyStories-valid.txt', 'r', encoding='utf-8') as f:\n",
        "   text=f.read()\n",
        "\n",
        "print(len(text))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18AQL63VB6SR",
        "outputId": "c6b69c7f-a13e-4b1b-938d-b99dad61e113"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step:0 train loss:3.739708185195923, val loss:3.7360925674438477\n",
            "step:500 train loss:1.4468269348144531, val loss:1.4616193771362305\n",
            "step:1000 train loss:1.1059880256652832, val loss:1.1338573694229126\n",
            "step:1500 train loss:0.9873049855232239, val loss:1.0126242637634277\n",
            "step:2000 train loss:0.9150543808937073, val loss:0.9438263773918152\n",
            "step:2500 train loss:0.875654935836792, val loss:0.9028713703155518\n",
            "step:3000 train loss:0.8363196849822998, val loss:0.8693223595619202\n",
            "step:3500 train loss:0.8099381923675537, val loss:0.83941650390625\n",
            "step:4000 train loss:0.7890445590019226, val loss:0.8213627338409424\n",
            "step:4500 train loss:0.7656910419464111, val loss:0.7986171245574951\n",
            "step:4999 train loss:0.746448814868927, val loss:0.7833225727081299\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"tinygptforcollab\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/19DiOjHtL-UEa69WlOcMsmRnkrNc5NmaS\n",
        "\"\"\"\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"tinygpt.ipynb\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/109yvdricQdl9D43KPCeh829Y89TGUcvC\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "#hypparameters\n",
        "import torch\n",
        "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters=200\n",
        "n_embd=384\n",
        "lr=3e-4\n",
        "batch_size=64\n",
        "block_size=256\n",
        "num_heads=6\n",
        "eval_inter=500\n",
        "dropout=0.2\n",
        "nlayerb=6\n",
        "max_iters=5000\n",
        "\n",
        "chars=sorted(list((set(text))))\n",
        "vocab_size=len(chars)\n",
        "\n",
        "itos={i:s for i, s in enumerate(chars)}\n",
        "stoi={s:i for i, s in enumerate(chars)}\n",
        "\n",
        "encode = lambda e: [stoi[c] for c in e]\n",
        "decode = lambda d: \"\".join([itos[c] for c in d])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data=torch.tensor(encode(text))\n",
        "n=int(0.9*len(data))\n",
        "train_data=data[:n]\n",
        "val_data=data[n:]\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "def get_batch(split):\n",
        "    data = train_data if split=='train' else val_data\n",
        "    ix=torch.randint(len(data)-block_size, (batch_size, ))\n",
        "    x=torch.stack([data[i:i+block_size]for i in ix])\n",
        "    y=torch.stack([data[i+1:i+block_size+1]for i in ix])\n",
        "    return x, y\n",
        "\n",
        "xb, yb=get_batch('train')\n",
        "\n",
        "import torch\n",
        "from torch import nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Head(nn.Module):\n",
        "   def __init__(self, head_size):\n",
        "    super().__init__()\n",
        "    self.key=nn.Linear(n_embd, head_size, bias=False)\n",
        "    self.query=nn.Linear(n_embd, head_size, bias=False)\n",
        "    self.value=nn.Linear(n_embd, head_size, bias=False)\n",
        "    self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "    self.ddp=nn.Dropout(dropout)\n",
        "   def forward(self, x):\n",
        "      B, T, C = x.shape\n",
        "      k=self.key(x)\n",
        "      q=self.query(x)\n",
        "      v=self.value(x)\n",
        "      wei=q@k.transpose(-2, -1) * k.shape[-1]**-0.5\n",
        "      wei=wei.masked_fill(self.tril[:T, :T]==0, float('-inf'))\n",
        "      wei=F.softmax(wei, dim=-1)\n",
        "      wei=self.ddp(wei)\n",
        "      if torch.isnan(wei).any() or torch.isinf(wei).any():\n",
        "          print(\"NaN or Inf values detected in the probability tensor.\")\n",
        "    # Add debugging information or further investigation her\n",
        "      else:\n",
        "         out=wei@v\n",
        "         return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "   def __init__(self, num_heads, head_size):\n",
        "      super().__init__()\n",
        "      self.heads=nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "      self.proj=nn.Linear(n_embd, n_embd)\n",
        "      self.ddp=nn.Dropout(dropout)\n",
        "   def forward(self, x):\n",
        "      out=torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "      out=self.ddp(self.proj(out))\n",
        "      return out\n",
        "\n",
        "\n",
        "class feedfoward(nn.Module):\n",
        "  def __init__(self, n_embd):\n",
        "    super().__init__()\n",
        "    self.net=nn.Sequential(nn.Linear(n_embd, 4*n_embd), nn.ReLU(), nn.Linear(4*n_embd, n_embd), nn.Dropout(dropout))\n",
        "  def forward(self, x):\n",
        "    ffd=self.net(x)\n",
        "    return ffd\n",
        "\n",
        "class Block(nn.Module):\n",
        "  def __init__(self, n_embd, num_heads):\n",
        "    super().__init__()\n",
        "    head_size=n_embd//num_heads\n",
        "    self.heads=MultiHeadAttention(num_heads, head_size)\n",
        "    self.ffd=feedfoward(n_embd)\n",
        "    self.lln=nn.LayerNorm(n_embd)\n",
        "  def forward(self, x):\n",
        "    x=x+self.heads(self.lln(x))\n",
        "    x=x+self.ffd(self.lln(x))\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "class BigramModel(nn.Module):\n",
        "    def __init__ (self):\n",
        "        super().__init__()\n",
        "        self.tokenembeddingtable=nn.Embedding(vocab_size, n_embd)\n",
        "        self.positionembeddingtable=nn.Embedding(block_size, n_embd)\n",
        "        self.heads=MultiHeadAttention(num_heads, n_embd//4)\n",
        "        self.ffd=feedfoward(n_embd)\n",
        "        self.block=nn.Sequential(*[Block(n_embd, num_heads=num_heads)for _ in range(nlayerb)])\n",
        "        self.lnf=nn.LayerNorm(n_embd)\n",
        "        self.lmhead=nn.Linear(n_embd, vocab_size)\n",
        "    def forward(self, idx, targets=None):\n",
        "        idx = idx.to(device)\n",
        "        B, T= idx.shape\n",
        "        tok_emb=self.tokenembeddingtable(idx)\n",
        "        pos_emb=self.positionembeddingtable(torch.arange(T, device=device))\n",
        "        x=tok_emb+pos_emb\n",
        "        x=self.block(x)\n",
        "        x=self.lnf(x)\n",
        "\n",
        "        logits=self.lmhead(x)\n",
        "\n",
        "\n",
        "        B, T, C =logits.shape\n",
        "\n",
        "        if targets is not None:\n",
        "          logits=logits.view(B*T, C)\n",
        "          targets=targets.to(device)\n",
        "\n",
        "          targets=targets.view(B*T)\n",
        "          loss=F.cross_entropy(logits, targets)\n",
        "        else:\n",
        "          loss=None\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "          idx_cong=idx[:, -block_size:]\n",
        "          logits, loss=self(idx_cong)\n",
        "          logits=logits[:, -1, :]\n",
        "          prob=F.softmax(logits, dim=-1)\n",
        "          idx_next=torch.multinomial(prob, num_samples=1)\n",
        "          idx=torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "\n",
        "        return idx\n",
        "@torch.no_grad\n",
        "def eval():\n",
        "    bm1.eval()\n",
        "    out={}\n",
        "    for split in ['train', 'val']:\n",
        "      losses=torch.zeros(eval_iters)\n",
        "      for k in range(eval_iters):\n",
        "         X, Y=get_batch(split)\n",
        "         logits, loss= bm1(X, Y)\n",
        "         losses[k]=loss\n",
        "      out[split]=losses.mean()\n",
        "    return out\n",
        "    bm1.train()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "bm1=BigramModel()\n",
        "bm1=bm1.to(device)\n",
        "\n",
        "optimizer=torch.optim.AdamW(bm1.parameters(), lr)\n",
        "\n",
        "\n",
        "for _ in range(max_iters):\n",
        "  xb, yb=get_batch(\"train\")\n",
        "  logits, loss=bm1(xb, yb)\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if _ % eval_inter==0:\n",
        "     losses=eval()\n",
        "     print(f\"step:{_} train loss:{losses['train']}, val loss:{losses['val']}\")\n",
        "  if _==4999:\n",
        "    losses=eval()\n",
        "    print(f\"step:{_} train loss:{losses['train']}, val loss:{losses['val']}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wz5lZGWKQDdN",
        "outputId": "7ec0ab38-1c22-496c-ba32-9171ba6d5ff5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Tommy cried over to the birds, house was very mighty. He has a car and a bell. He wanted to share his house. He opened his owner and told his friends to eat.\n",
            "So, they added each other's peaceful search. The man bit his hand. But he needed it safe again. He missed his problems and peaceful. As they did, they moved away, dancing in front of his own peace. He was so grateful that he could help the buttons over. He saiked, \"Don't worry, I don't come back.\n",
            "<|endoftext|>\n",
            " \n",
            "Once there was a little girl who loved like her smooth. She always smiled at her mommy sound and let her patch her.\n",
            "One day, the little girl was getting closer, and the girl jumped outfits of the door to the ground. She tried to grumble to do it, but that they were bunny. She was faster and grateful, so it passed TV.\n",
            "They had so much fun that they could go home. After they had, the polm decided to kay. \n",
            "The little girl was so happy! She was very proud and she spraised the baby movies. \n",
            "She put on her new toy crys, but they did not like to pull them. She lifted the tree and hid it uffer. So, Sam's mom gave her the frustry venture.\n",
            "The little girl stopped and suddenly trying on the box. She felt a lot time and trying to fly herself and drinkly early around. She pulled and pulled out herself in the sky.\n",
            "<|endoftext|>\n",
            "\n",
            "Lily and Ben were brothers. They liked to play with their toy and open their toys. Lily loved to play outside in the sunshine. She pulled and animals, hand their mommy got hurt by brothers.\n",
            "One day, Mommy got his mommy told him that he sounded come. He pulled the rare red, \"I thought to hold out the branches together!\"\n",
            "The driver smiled and said, \"No, Timmy. It's my adventure.\"\n",
            "But then they got on him caught the park. Timmy and his mommy forgot about him again!\n",
            "<|endoftext|>\n",
            "Once upon a time, there was a little girl named Lily. She had a fancy sound of earthers. One day, she wanted to do something else with her mommy. Lily was very sad and curious about the crystal. She had long brown things, but all she knew this day. She was happy to be careful and helped her together celebration and be kind on those.\n",
            "One day, Lily wanted to try it, so she decided to keep her from the car. It was her mom said, \"but be careful. She wanted to try it, so go!\" Mom and Dad threw the bookshelf, hocked tightly and spent to her neighborhood.\n",
            "<|endoftext|>\n",
            "Once upon a time, there was a little girl named Lily. She loved to deliver the books and thank you for times. One day, Lily and her mommy gave her a cute plant and a second. She looked at the dog and said, \"Good book! Let's go home.\"\n",
            "Lily curled up the cute too. She showed them very marbles and put them all the time. She said, \"I want to go so the tool!\"\n",
            "They shook her head. It never forgot the dog again. They wanted to show each other again.\n",
            "<|endoftext|>\n",
            "\n",
            "Ben lived in a big smoketle. He looked at the orange fort and he saw a big bear. He saw opened the park with many oranges. He had many hats and lots of adventures to play.\n",
            "When he opened the bear, he saw that he was magic found. He reached the tooth course. He felt joy and happy.\n",
            "But he was too bored! he lit the boat very became and safe, and ut he liked to sing. He was so the tears and put it back. He asked his mom barking the with a rare coli are friendly. They made everyone that made the boats sound, when they were letting. It was worried and neighedled and it sounded. They were so grateful, but they had never seen so much.\n",
            "Jane held the colorful cloudser they set on a new dress. After pushing the car, they sailed down from the tree to find them. \n",
            "They weighed and smiled. Soon, they saw a lot of books and pick. At the bookstorm was glad that sometimes bad and stretching them on top. They had many things together all the careful juice. \n",
            "When they arrived at the curtain snow. They discussed and discussed and had something cold right away. \n",
            "Then, they parked all some pents out in the curtains and hooked her a funlug time until they were draining on a hat. \n",
            "Jack's sunset so was all the pents were in them. Jack went outside to play and draw kept waiting now. He was calling him for help. He saw his friends and was amazed. He took the chest birthday, but he knew he had to go home. \n",
            "But then, he did something special. It had told them. Man wrote them and she could both. It was so much better. It made a nett too. He wrapped in filth, puzzle, and laughed. \n",
            "Lucy told the day every day. She did she had graced on that she didn't know how to touch sharp. She ate it with her chickens together. \n",
            "The nett was an unusual red black to share. He was so surprised and climbed down on the dark too. Then she gived all the toys. The black knew that even day, he kneeled that sometimes what her mom told him to take him to teach him.\n",
            "<|endoftext|>\n",
            "\n",
            "Once upon a time, there were lots of coins. She was blowns, and her strong blocks in the corner.\n",
            "Her dad slowly came to see them, and they brought the costuch it back. The cobweb said he wanted to go on an adventure.\n",
            "The cobwebs asked if she wanted to move. Soday they did it in the dress and sprayed watermelon who was over after they had helped each other.\n",
            "But they prodded much looking at their mom and to help atte lots of ground. Nothing to find them to play away.\n",
            "The moral together, and they played together every day. Mom had the grounds exploring together.\n",
            "<|endoftext|>\n",
            "\n",
            "Sara and Ben are friends. They like to play with their toys. They have fun games and books. They did not move. They do not like the box anymore. They did not noticed any iglo-and. They do not uncle to see others.\n",
            "Sara and Ben pushes. They wish their legs ashear. They want to play with buttons.\n",
            "\"Let's play with the moter!\" Sara says.\n",
            "They run fast and cups. They prwise blings again. They get down to play. They are happy.\n",
            "They only sorry lemon looks at the small ground. They wish Mom is loud and lonely. They help each other, too. They kick, they peted the floor and hurt the chicks. They are happy.\n",
            "<|endoftext|>\n",
            "\n",
            "Lily and Tom are three years old. They like to play with chalk. But they count in his room. They have fun with their blocks. They do not care of the rocks. Anna says, \"Let's have fun that back together.\"\n",
            "\"I am proud of you!\" Ben says, pouring their blocks. \"I know, look at them, honey. I think my dears for being so flowers. He sees a lrocket into the rock.\"\n",
            "Sara and Mom looks at the lid. They smile thanks together. They see a big and strung. They see lots of dears. They see parks. They count. They hurn. They see a small pot. Annie tries to gues where it is. They told strong their rocks. They think for a long time. They tell the pot.\n",
            "Their sens2. She runs too and sang at Lily. She has a big shark. She grows at them.\n",
            "Ben is deaf. He looks at the pot. He thinks herself. He boughts abour and splashes. He have knows not oknothers. He enjoys the letter. He sees the wince. He signs.\n",
            "Sam is curious. He took Sam's book. He says, \"He can make our words. He is whistly at being spots.\"\n",
            "Sam and Lily nod. They think they went inside to go home. They put on their hats nows. But The hing blocks on the trade. He tries to budge. He fell ashamed. He jumps in the kitchen.\n",
            "Anna got some strawberry and secream. She cries were small. One day, Lily was playing with her pump and checked it.\n",
            "Lily and Ben forgot about the kitten pillow in the kitchen. They ate from the kitchen's yard. They looked on the kitchen. They had a big, hairy come out of the lotion.\n",
            "Lily and Tom were raining and harder. They all wanted to see the stone. They waited for Sam's bath. They ate the chess shiver.\n",
            "They hugged Mom and said they were the pritty. Tom had a lot of fun. He said, \"I know, print me tore count this rainbow, people. I like my chess.\"\n",
            "Sam was smart, so strange Bill nodded and protecting herself. He liked the chess and helder. He hoped her toy, dog, sweet and strange. He did not friends. He saw the tables, but he could not. He turned them, continued. Jill didn't like Sam remove from near the block on the stranger.\n",
            "But then he remembered that he had nothing to do. His mommy saw him and said, \"It's okay, what have you doing?\"\n",
            "His mommy smiled back and sailed with the dog and they were fighting.\n",
            "Sam and Jimmy kept kicking up his special. They kicked their page and made lots of paper place! They made his good fork and checked up the little girl. After a sudden nervous of the doll and made her decorations. They were going to make a weape way because of paper from flying into the paper. \n",
            "When they arrived it was looking, Sue saw so many other intersting. Her friends over had more content to other animals. But they had to be careful and to kick their masks. Mark was so happy!\n",
            "<|endoftext|>\n",
            "\n",
            "Once upon a time there was a little girl named Jill. She loved cone. Everywhere she went, she would cove to her mouth and play with her not store. There was mreluctions, Tim always could come from trying special.\n",
            "One day Sunday, a raccie comes to the tree in the corner gathered. Percies were extra that neight about order for him. He loved excitecly and became a cool cupcle and was so happy. They could help the cow with the delicious colors.\n",
            "Sunny kept practicing and wam colf! Searsuns could out at the colorful colors and some ice cool. His eyes were very good to find one zooming around it. Comes Fredgen easily agoes. One day, Red found a small blue soft new home.\n",
            "\"It's silly, but be careful,\" she said. \". It hurts my nockets with it!\". \n",
            "Durincless maded even more people and went to the softle nearbyâ€‹. \n",
            "Then, a big, cause blue sky in the woods care.\n",
            "When each cones were busy and apping, he made surious. He spurred adventure so his grandpared his notes that looks so special!\n",
            "<|endoftext|>\n",
            "\n",
            "Jenny and Mary was a monster and he felt proud of him for his one day. They played home and exploring it until had thrunks! He did lots of his head flute and wiped mud in the movies. He asked his mom and said, \"What's your hat is, Jax? This is a furry special view, will to try it out.\"\n",
            "Jack reached on tour around the barn to join i\n"
          ]
        }
      ],
      "source": [
        "n_of_tokens=10000 #no of tokens to generate\n",
        "print(decode(bm1.generate(torch.zeros((1, 1), dtype=torch.long, device=device), n_of_tokens)[0].tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDZRkjxQQP8G"
      },
      "outputs": [],
      "source": [
        "PATH='/content/drive/MyDrive/tinygpttinystories.pt'\n",
        "torch.save(bm1.state_dict(), PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7gmTP6pXv1_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
